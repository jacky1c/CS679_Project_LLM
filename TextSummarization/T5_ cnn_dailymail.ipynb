{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUnZ551e8HaO","executionInfo":{"status":"ok","timestamp":1680381764571,"user_tz":240,"elapsed":878,"user":{"displayName":"project 474","userId":"03542890771905654125"}},"outputId":"e0aaf26a-65e5-4e3a-fc72-0dae49948374"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os"]},{"cell_type":"code","source":["from drive.MyDrive.TextSummarization import *"],"metadata":{"id":"DEUbqpXk8yqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir('drive/MyDrive/TextSummarization')"],"metadata":{"id":"FHWCpLrx-xbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG-JaPDTZj17","executionInfo":{"status":"ok","timestamp":1680381799055,"user_tz":240,"elapsed":151,"user":{"displayName":"project 474","userId":"03542890771905654125"}},"outputId":"2c2cb95c-dbe9-40e3-b6c2-ad3bad206cc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" README.md\t\t\t   run_summarization.py       transformers\n"," requirements.txt\t\t   T5_cnn_dailymail\n"," run_summarization_no_trainer.py  'T5_ cnn_dailymail.ipynb'\n"]}]},{"cell_type":"code","source":["!pip install datasets\n","!pip install evaluate\n","!pip install rouge_score\n","# # !pip install transformers\n","!rm -r transformers\n","!git clone https://github.com/huggingface/transformers.git\n","!cd transformers\n","!pip install -q ./transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ispGi3WS_5El","executionInfo":{"status":"ok","timestamp":1680383153416,"user_tz":240,"elapsed":5223,"user":{"displayName":"project 474","userId":"03542890771905654125"}},"outputId":"1e20f24d-57d7-492d-a550-a89d48392517"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.1.1)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=732fe1edaef2ddc087f5be1e5f6727c6383f768bf39daf33236014bdea0d1771\n","  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["os.mkdir(\"/content/drive/MyDrive/TextSummarization/T5_cnn_dailymail/\") "],"metadata":{"id":"f_lwYtthHow3","executionInfo":{"status":"error","timestamp":1680381917962,"user_tz":240,"elapsed":160,"user":{"displayName":"project 474","userId":"03542890771905654125"}},"colab":{"base_uri":"https://localhost:8080/","height":169},"outputId":"41d2a025-6287-482d-fd09-90e1cfee72e5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-1b92c0099571>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/TextClassification/T5_cnn_dailymail/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/TextClassification/T5_cnn_dailymail/'"]}]},{"cell_type":"code","source":["%reload_ext tensorboard"],"metadata":{"id":"KFNgE8k-Ii6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir /content/drive/MyDrive/TextSummarization/T5_cnn_dailymail/runs"],"metadata":{"id":"XnGjimN9IpLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python run_summarization.py \\\n","    --model_name_or_path t5-small \\\n","    --do_train \\\n","    --do_eval \\\n","    --dataset_name cnn_dailymail \\\n","    --dataset_config \"3.0.0\" \\\n","    --source_prefix \"summarize: \" \\\n","    --num_train_epochs 2 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate \\\n","    --output_dir /tmp/T5_cnn_dailymail/ \\\n","    --logging_steps 360 \\\n","    --logging_dir /content/drive/MyDrive/TextSummarization/T5_cnn_dailymail/runs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dORjh_x_k08","outputId":"ac48080b-d058-42ac-aac7-e0bc3dbdea00","executionInfo":{"status":"ok","timestamp":1680384017887,"user_tz":240,"elapsed":30415,"user":{"displayName":"project 474","userId":"03542890771905654125"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-01 21:19:52.405640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","04/01/2023 21:19:55 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/01/2023 21:19:55 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/TextClassification/T5_cnn_dailymail/runs,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=360,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=2.0,\n","optim=adamw_hf,\n","optim_args=None,\n","output_dir=/tmp/T5_cnn_dailymail/,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/tmp/T5_cnn_dailymail/,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/01/2023 21:19:56 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de\n","04/01/2023 21:19:56 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","04/01/2023 21:19:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de\n","04/01/2023 21:19:56 - WARNING - datasets.builder - Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n","04/01/2023 21:19:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de\n","100% 3/3 [00:01<00:00,  2.14it/s]\n","[INFO|configuration_utils.py:668] 2023-04-01 21:19:57,534 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/config.json\n","[INFO|configuration_utils.py:720] 2023-04-01 21:19:58,313 >> Model config T5Config {\n","  \"_name_or_path\": \"t5-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","[INFO|tokenization_auto.py:494] 2023-04-01 21:19:58,411 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:668] 2023-04-01 21:19:58,501 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/config.json\n","[INFO|configuration_utils.py:720] 2023-04-01 21:19:58,501 >> Model config T5Config {\n","  \"_name_or_path\": \"t5-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","[INFO|tokenization_utils_base.py:1809] 2023-04-01 21:19:58,691 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/spiece.model\n","[INFO|tokenization_utils_base.py:1809] 2023-04-01 21:19:58,691 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/tokenizer.json\n","[INFO|tokenization_utils_base.py:1809] 2023-04-01 21:19:58,692 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1809] 2023-04-01 21:19:58,692 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1809] 2023-04-01 21:19:58,692 >> loading file tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:668] 2023-04-01 21:19:58,692 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/config.json\n","[INFO|configuration_utils.py:720] 2023-04-01 21:19:58,693 >> Model config T5Config {\n","  \"_name_or_path\": \"t5-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","[INFO|modeling_utils.py:2451] 2023-04-01 21:19:58,789 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/pytorch_model.bin\n","[INFO|configuration_utils.py:575] 2023-04-01 21:19:58,917 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.28.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:3100] 2023-04-01 21:19:59,758 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:3108] 2023-04-01 21:19:59,758 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:537] 2023-04-01 21:19:59,855 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/generation_config.json\n","[INFO|configuration_utils.py:575] 2023-04-01 21:19:59,856 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.28.0.dev0\"\n","}\n","\n","04/01/2023 21:20:02 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de/cache-def5cc97705658fb.arrow\n","04/01/2023 21:20:02 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de/cache-3e9492622d9bd55e.arrow\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","[INFO|trainer.py:1746] 2023-04-01 21:20:04,047 >> ***** Running training *****\n","[INFO|trainer.py:1747] 2023-04-01 21:20:04,047 >>   Num examples = 287113\n","[INFO|trainer.py:1748] 2023-04-01 21:20:04,047 >>   Num Epochs = 2\n","[INFO|trainer.py:1749] 2023-04-01 21:20:04,047 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:1750] 2023-04-01 21:20:04,047 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n","[INFO|trainer.py:1751] 2023-04-01 21:20:04,047 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1752] 2023-04-01 21:20:04,047 >>   Total optimization steps = 143558\n","[INFO|trainer.py:1753] 2023-04-01 21:20:04,048 >>   Number of trainable parameters = 60506624\n","  0% 0/143558 [00:00<?, ?it/s][WARNING|logging.py:280] 2023-04-01 21:20:04,107 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","  0% 33/143558 [00:12<13:51:24,  2.88it/s]Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/TextClassification/run_summarization.py\", line 751, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/TextClassification/run_summarization.py\", line 678, in main\n","    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 1639, in train\n","    return inner_training_loop(\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 1906, in _inner_training_loop\n","    tr_loss_step = self.training_step(model, inputs)\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 2670, in training_step\n","    loss.backward()\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\", line 488, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","  0% 33/143558 [00:12<15:20:36,  2.60it/s]\n","^C\n"]}]}]}